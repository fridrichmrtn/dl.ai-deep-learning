{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence models & attention mechanism\n",
    "\n",
    "## Various seq2seq architectures\n",
    "\n",
    "\n",
    "* sequence-to-sequence models (ie machine translation)\n",
    "    * [paper](https://arxiv.org/pdf/1409.3215)\n",
    "    * [paper](https://arxiv.org/pdf/1406.1078)\n",
    "    * architecture\n",
    "        * encoder network (input sentence, outputs a vector representation)\n",
    "        * decoder network (input a vector representation, outputs translation)\n",
    "* image captioning\n",
    "    * [paper](https://arxiv.org/pdf/1412.6632)\n",
    "    * [paper](https://arxiv.org/pdf/1411.4555)\n",
    "    * [paper](https://arxiv.org/pdf/1412.2306)\n",
    "    * architecture\n",
    "        * encoder network (headless cnn ie alexnet)\n",
    "        * decoder network (input a pic representation, outputs caption)\n",
    "\n",
    "* the most likely sentence\n",
    "    * machine translation (\"conditional language model\")\n",
    "        * $P(y^{<1>},...,y^{<T_x>} | x^{<1>},...,x^{<T_x>})$\n",
    "            * probability of english sentence conditioned on input french sentence\n",
    "            * in the translation problem, we are maximizing the probability of the translation\n",
    "            * done by beam search, greedy search wont work as we optimize for whole sentence, not token\n",
    "\n",
    "* beam search algorithm\n",
    "    * try to pick a first $b$ number of words based on $P(y^{<1>}|x)$, $b$ is considered beam width\n",
    "        * using encoding net on whole sentence, from the first step of the decoder net pick $b$ most likely\n",
    "    * based on selected words, pick most likely following words using $P(y^{<2>}|x, y^{<1>})$ \n",
    "        * using encoding net on whole sentence, continue with the second step of the decoder based on a first word\n",
    "        * $P(y^{<1>},y^{<2>}|x) = P(y^{<1>}|x) P(y^{<2>}|x, y^{<1>})$ \n",
    "        * evaluating for the vocabulary, picked only $b$ words in total (might remove previous option if a chosen word is not part of the sentence)\n",
    "    * continuing until hitting \\<EOS\\> token $b$ times \n",
    "\n",
    "* beam search refinements\n",
    "    * utility func\n",
    "        * $arg max \\ y\\ \\Pi_{t=1}^{T_y} P(y^{<t>} | x, y^{<1>},...,y^{<t-1>} )$, see parts above\n",
    "        * $arg max \\ y\\ \\Pi_{t=1}^{T_y} log \\ P(y^{<t>} | x, y^{<1>},...,y^{<t-1>} )$, to battle num overflow\n",
    "        * $arg max \\ y\\ \\frac{1}{T_y^{\\alpha}}\\Pi_{t=1}^{T_y} log \\ P(y^{<t>} | x, y^{<1>},...,y^{<t-1>} )$, to normalize for length $\\alpha$ between 0 and 1\n",
    "        * evaluate all generated sentences with the utility func\n",
    "    * how to set $b$?\n",
    "        * if $b$ large better results but slow, if $b$ small worse results, but fast \n",
    "\n",
    "* beam search error analysis\n",
    "    * RNN vs beam components\n",
    "    * RNN computes $P(y|x)$, compute human translation (better) and model translation, compare the two\n",
    "        * if human translation scores higher P, work on beam search, otherwise on RNN\n",
    "        * table for multiple translations\n",
    "\n",
    "* bleu (bi-lingual evaluation understudy) score\n",
    "    * [paper](https://aclanthology.org/P02-1040.pdf)\n",
    "    * a tool for evaluating multiple good answers (translations)\n",
    "    * modified precision: (max # words observed)/(# words predicted)\n",
    "        * bi-grams: getting # max bi-grams observed, # bi-grams predicted\n",
    "        * modified bi-gram precision: (sum # max bi-grams observed)/(sum # bi-grams predicted)\n",
    "        * can be generalized for n-grams, conventionally calculated for 1-4 grams\n",
    "        * $BP \\ e^{\\frac{1}{4}\\sum_{n=1}^{4}PRE_n}$, where $BP = 1$ if the machine translation longer than reference, else $BP = e^{1-l_{ref}/l_{mt}}$\n",
    "\n",
    "* attention model\n",
    "    * [paper](https://arxiv.org/pdf/1409.0473)\n",
    "    * addresses problems with longer texts, where encoder-decoder approach shows diminishing returns\n",
    "    * intuition\n",
    "        * input foreign text\n",
    "        * bidirectional RNN, compute features for each of the tokens\n",
    "        * attention to particular tokens (to translate the a token, we need to understand its context)\n",
    "        * output RNN, takes its state, already translated  tokens and context of a current token (features of relevant token for a particular token we want to translate) as inputs to translate current token\n",
    "    * algorithm\n",
    "        * input foreign text\n",
    "        * bidirectional RNN\n",
    "            * for every step we consider activations $a^{<t'>}= (\\overleftarrow{a}^{<t'>}, \\overrightarrow{a}^{<t'>})$\n",
    "        * attention\n",
    "            * for each of the input tokens, it looks at the bidirectional RNN outputs and computes attention $\\alpha^{<t,t'>}$, which informs the output RNN how much of a context from each token is needed\n",
    "            * $\\sum_{t'} \\alpha^{<t,t'>} = 1$, for $\\alpha^{<t,t'>} \\geq 0$\n",
    "            * $c^{<t>} = \\sum_{t'} \\alpha^{<t,t'>} a^{<t'>}$, that is a weighted sum of attention and activations from bidirectional RNN\n",
    "        * traditional RNN\n",
    "            * inputs context $c$\n",
    "            * inputs state $S^{<t'>}$\n",
    "            * inputs a previous token\n",
    "            * outputs a token\n",
    "    * computing attention\n",
    "        * $\\alpha^{<t,t'>}$ = amount of attention $y^{<t>}$ should pay to $a^{<t'>}$\n",
    "        * $\\alpha^{<t,t'>} = \\frac{exp(e^{<t,t'>})}{\\sum_{<t'>}^{<T_x>} exp(e^{<t,t'>})}$, softmax to make sure $\\sum_{t'} \\alpha^{<t,t'>} = 1$\n",
    "        * $e^{<t,t'>}$ is computed by feed-forward net using previous output RNN state $s^{<t-1>}$ and $a^{<t'>}$ as its inputs\n",
    "        * unfortunately quadratic costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Speech recognition\n",
    "\n",
    "* input audio clip -> text transcript\n",
    "* spectrograms (audio clip representation), shows time (x) vs frequency (y) vs energy (coloring)\n",
    "* phonemes -> basic units of voice sounds (hand-engineered)\n",
    "* large datasets allows for e2e speech recognition systems\n",
    "* attention vs ctc models\n",
    "    * ctc -> large inputs, outputs (transcripts) limited -> collapse repeated characters not separated by \"blank\"\n",
    "* trigger word detection (wake up word)\n",
    "    * spectrogram, fed into RNN, labels are 1 after the trigger word, 0 otherwise\n",
    "    * usually imbalanced"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
