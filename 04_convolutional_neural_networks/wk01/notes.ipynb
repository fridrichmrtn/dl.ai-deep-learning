{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations of CNN\n",
    "\n",
    "* used mostly in computer-vision problems such as image classification, object detection, style transfer, others\n",
    "* images may lead to large inputs (and consequently very large networks)\n",
    "\n",
    "## Convolution operation\n",
    "\n",
    "**Convolution**  \n",
    "* image (6 x 6) * filter (3 x 3) = result (4 x 4)\n",
    "    * (n x n) * (f x f) = (n-f+1 x n-f+1)\n",
    "        * f usually odd\n",
    "        * not full detection, image shrinks -> padding (adding pixels around)\n",
    "        * if p denotes padding size then the result size is (n+2p-f+1 x n+2p-f+1)\n",
    "        * valid convolution (no padding)\n",
    "            * (n x n) * (f x f) = (n-f+1 x n-f+1)\n",
    "        * same convolution (output size is same as original input size)\n",
    "            * (n+p x n+p) * (f x f) = (n+2p-f+1 x n+2p-f+1)\n",
    "            * p = (f-1)/2  \n",
    "* in some textbooks, filters are rotated (mirrored) before doing the transformation (to allow for associations), by convention this is not used in deep learning literature\n",
    "* filters can be learned through weights (!)        \n",
    "    \n",
    "Algorithm \n",
    "* sliding filter window into the image, multiplying filter with the image values, adding them together and putting them into the result matrix\n",
    "* sliding through the whole image from left to right (by 1 pixel), from top to down (by 1 pixel)\n",
    "* result matrix is filled, serves as filter detection (could be ie edge filter)\n",
    "* python: `conv-forward` tensorflow: `tf.nn.conv2d` keras: `tf.kearas.Conv2D`\n",
    "\n",
    "**Strides**\n",
    "* strides (movement by pixels) different from 1 can be used for the filter window\n",
    "* (n+p x n+p) * (f x f) = ([(n+2p-f)/s+1] x [(n+2p-f)/s+1])\n",
    "    * s is stride, if the fraction is not integer we round down\n",
    "\n",
    "**Volumes**\n",
    "* image (6 x 6 x 3) * filter (3 x 3 x 3) = result (4 x 4)  \n",
    "* detection across color channels (can look at one or all)\n",
    "* multiple filters can be applied at the same time resulting in stacking the 2d outputs (the last dimension of the result is driven by number of convolution filters)\n",
    "\n",
    "Algorithm\n",
    "* put filter into the starting position, do element-wise multiplication for     corresponding elements\n",
    "* sum the result and add it to the result matrix\n",
    "* move the filter by stride and repeat until the result matrix is filled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One layer of CNN\n",
    "\n",
    "* number of params -> (filter size + bias) * number of filters\n",
    "* notation for layer $l$\n",
    "    * $m$ -> training examples\n",
    "    * $f^{[l]}$ -> filter size\n",
    "    * $p^{[l]}$ -> padding\n",
    "    * $d^{[l]}$ -> stride\n",
    "    * $n_c^{[l]}$ -> number of filters\n",
    "    * $f^{[l]}$ x $f^{[l]}$ x $n_c^{[l-1]}$ -> size of a filter, last dimension same as the number of channels in previous layer\n",
    "    * $f^{[l]}$ x $f^{[l]}$ x $n_c^{[l]}$ -> activations\n",
    "    * $m$ x $f^{[l]}$ x $f^{[l]}$ x $n_c^{[l]}$-> vectorized activations\n",
    "    * $f^{[l]}$ x $f^{[l]}$ x $n_c^{[l-1]}$ x $n_c^{[l]}$ -> weights\n",
    "    * $n_c^{[l]}$ -> bias\n",
    "\n",
    "* input -> $n_h^{[l-1]}$ x $n_w^{[l-1]}$ x $n_c^{[l-1]}$  \n",
    "* output -> $n_h^{[l]}$ x $n_w^{[l]}$ x $n_c^{[l]}$, where $n_h^{[k]}= [\\frac{n_w^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1]$, see less formally written version above\n",
    "\n",
    "* forward step (one filter)\n",
    "    * volume calculation (sliding, element-wise multiplication and sum)\n",
    "    * adding bias\n",
    "    * feeding the resulting matrix into an activation function\n",
    "    * stacking filters together (output of the convolution layer)\n",
    "    * ([(n+2p-f)/s+1] x [(n+2p-f)/s+1] x number of filters)\n",
    "\n",
    "* backward step ?\n",
    "\n",
    "\n",
    "## Deep CNN\n",
    "\n",
    "* for the parameters of convolution filters, formulas above apply\n",
    "* common architecture -> convolution filter shrink and number of channels increases\n",
    "* in the last step, filters are unrolled to one long vector which is fed into output layer\n",
    "\n",
    "**Pooling layer**  \n",
    "* max pooling -> input matrix divided into regions, returns max for each region\n",
    "    * filter size & stride as pooling hyper params (defines regions)\n",
    "    * no parameters to learn (fixed function)\n",
    "    * intuition -> in case filter feature is detected, keep large number (the feature was detected)\n",
    "    * done independently on each of the channel\n",
    "    * ([(n+2p-f)/s+1] x [(n+2p-f)/s+1] x number of channels)\n",
    "    \n",
    "* average pooling -> input matrix divided into regions, returns avg for each region\n",
    "    * not used that often (unless in very deep NNs for reducing the input)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
