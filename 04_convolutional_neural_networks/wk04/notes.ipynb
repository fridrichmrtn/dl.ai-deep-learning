{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Special applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Face recognition\n",
    "\n",
    "* face verification (input image & person ID are same, 1:1) vs recognition (check input image against DB, 1:n problem, higher accuracy needed)\n",
    "* one shot learning problem -> recognition based on 1 example (!)\n",
    "* traditional CNN wont work, similarity function learning does\n",
    "* d(img1,img2)<= t, it is the same person, otherwise no\n",
    "\n",
    "### Siamese network\n",
    "\n",
    "* [paper](https://arxiv.org/pdf/1701.01876)\n",
    "* CNN, pooling, FC deeper in the network as a representation of a picture\n",
    "* the difference between images can be calculated as $d(x^{(1)},x^{(2)})= \\|{f(x^{(1)})-f(x^{(2)})}\\|^2_2$\n",
    "* the params of the NN are learned such as the distance for the same person is small and large in other cases\n",
    "\n",
    "### Triplet loss function\n",
    "\n",
    "* [paper](https://arxiv.org/pdf/1503.03832)\n",
    "* anchor image A  vs positive example (same person) P vs negative example (different image) N\n",
    "    * $\\| f(A)-f(P) \\|^2 \\leq \\| f(A)-f(N)\\|^2 $, that is $d(A,P) \\leq d(A,N)$\n",
    "    * $ \\| f(A)-f(P)\\|^2  - \\| f(A)-f(N) \\|^2 <=0$, this can be trivially satisfied with distance func always 0\n",
    "    * $ \\| f(A)-f(P)\\|^2  - \\| f(A)-f(N) \\|^2 + \\alpha <=0 $, solved by adding a margin $\\alpha$\n",
    "* loss function\n",
    "    * $ L(A,P,N) = \\max(\\| f(A)-f(P)\\|^2  - \\| f(A)-f(N) \\|^2 + \\alpha,0) $, ie if objective achieved the loss is 0, otherwise positive loss\n",
    "* cost function\n",
    "    * $ J = \\sum_{i=1}^n L(A^{(i)},P^{(i)},N^{(i)}) $\n",
    "* training \n",
    "    * multiple images needed (ie 10k pics of 1k persons)\n",
    "    * choosing hard triplets for training, where $d(A,P) \\sim d(A,N)$\n",
    "\n",
    "\n",
    "### Face verification & binary classification\n",
    "\n",
    "* deeper image representations into a a logit in the output layer (classifier outputs whether same person or not)\n",
    "* logit/sigmoid can be applied on the difference of the encoding such as $\\hat{y} = \\sigma(\\sum_{k=1}^{128} w_k|f(x^{(i)})_k-f(x^{(j)}_k)|+b)$\n",
    "    * multiple way of distance measures can be considers such as chi-quadrat similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Neural transfer\n",
    "\n",
    "* [paper](https://arxiv.org/pdf/1508.06576)\n",
    "* learned representation [paper](https://arxiv.org/pdf/1311.2901)\n",
    "    * pick a unit in layer 1, visualize image patches that maximize units activation\n",
    "        * repeat for other units\n",
    "        * color gradients, lines, etc\n",
    "    * pick a unit in a deeper layer, visualize image patches that maximize units activation\n",
    "        * repeat for other units\n",
    "        * textures\n",
    "    * pick a unit in a deeper layer, visualize image patches that maximize units activation\n",
    "        * repeat for other units\n",
    "        * part of objects, part of animals, etc\n",
    "    * pick a unit in a deeper layer, visualize image patches that maximize units activation\n",
    "        * repeat for other units\n",
    "        * whole objects, animals, people, text, ...    \n",
    "\n",
    "### Cost function\n",
    "\n",
    "* C content image, S style image, G generated image, exploration of learned representation needed,\n",
    "* $J(G) = \\alpha \\cdot J_{content}(C,G) + \\beta \\cdot J_{style}(S,G)$, denotes the costs weighting content and style elements of the generated image, which is further governed by the parameters,\n",
    "* algorithm,\n",
    "    * initiate G randomly,\n",
    "    * use gradient descent to minimize J(G), $G = G -\\frac{\\delta}{\\delta G} J(G)$.\n",
    "\n",
    "### Content cost function\n",
    "\n",
    "* we use a layer $l$ to compute content cost, $l$ is in between the shallow and deep layers,\n",
    "* pre-trained net can be used (Inception, VGG, ...),\n",
    "* let $a^{[l],(C)}$ and $a^{[l],(G)}$ be the activation of layer $l$ on the images,\n",
    "* if the activations are similar, the content is similar,\n",
    "* $J_{content}(C,G) = \\frac{1}{2} \\|a^{[l],(C)} - a^{[l],(G)}\\|^2$, ie element wise differences between the activations.\n",
    "\n",
    "### Style cost function\n",
    "\n",
    "* we use a layer $l$ to measure style,\n",
    "* style is defined as correlation between activations across conv channels\n",
    "    * if the channels are correlated, it means that there are tight to somewhat similar type of objects (ie texture and lines)\n",
    "    * if there are not correlated, they are not usually seen together (texture, shapes, ...)\n",
    "    * this can be leveraged to comparing style and generated images\n",
    "* style matrix (measuring the correlations)\n",
    "    * let $a^{[l]_{i,j,k}}$ activation at (i, j, k) that represents h, w, ch\n",
    "    * $G^{[l]}$ is a matrix of size $n_c^{[l]}$ x $n_c^{[l]}$, that is computing corr between channels k and k' such as $G^{[l]}_{k,k'}$ \n",
    "    * $G^{[l]}_{k,k'} = \\sum_i^{n_h^{[l]}} \\sum_j^{n_w^{[l]}} a^{[l]}_{i,j,k} a^{[l]}_{i,j,k'}$, un-normalized cross/variance not really corr\n",
    "    * $G^{[l](S)}_{k,k'} = \\sum_i^{n_h^{[l]}} \\sum_j^{n_w^{[l]}} a^{[l](S)}_{i,j,k} a^{[l](S)}_{i,j,k'}$\n",
    "    * $G^{[l](G)}_{k,k'} = \\sum_i^{n_h^{[l]}} \\sum_j^{n_w^{[l]}} a^{[l](G)}_{i,j,k} a^{[l](G)}_{i,j,k'}$ \n",
    "    * $J_{style}^{[l]} (S,G) = \\frac{1}{(2 n_h^{[l]} n_w^{[l]} n_c^{[l]})^2} ( \\sum_k \\sum_{k'} (G_{kk'}^{[l][S]}-G_{kk'}^{[l][G]}))^2$\n",
    "\n",
    "* it is good to use style cost function for multiple different layers such as $J_{style} (S,G) = \\sum_l \\lambda^{[l]} J_{style}^{[l]} (S, G)$\n",
    "* and the goal is to optimize $J(G) = \\alpha \\cdot J_{content}(C,G) + \\beta \\cdot J_{style}(S,G)$\n",
    "\n",
    "### Conv generalization\n",
    "\n",
    "* convolution can be generalized to 1D, 2D, or 3D data\n",
    "* for 3D volume, we need 3D filter\n",
    "    * input 3D volume and a channel 14 x 14 x 14 x 1\n",
    "    * 16 3D filters (5 x 5 x 5 x 1)\n",
    "    * output (10 x 10 x 10 x 16)\n",
    "    * 32 3D filters (5 x 5 x 5 x 16)\n",
    "    * output (6 x 6 x 6 x 32)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
