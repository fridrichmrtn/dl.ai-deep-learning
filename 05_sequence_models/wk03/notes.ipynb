{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence models & attention mechanism\n",
    "\n",
    "## Various seq2seq architectures\n",
    "\n",
    "\n",
    "* sequence-to-sequence models (ie machine translation)\n",
    "    * [paper](https://arxiv.org/pdf/1409.3215)\n",
    "    * [paper](https://arxiv.org/pdf/1406.1078)\n",
    "    * architecture\n",
    "        * encoder network (input sentence, outputs a vector representation)\n",
    "        * decoder network (input a vector representation, outputs translation)\n",
    "* image captioning\n",
    "    * [paper](https://arxiv.org/pdf/1412.6632)\n",
    "    * [paper](https://arxiv.org/pdf/1411.4555)\n",
    "    * [paper](https://arxiv.org/pdf/1412.2306)\n",
    "    * architecture\n",
    "        * encoder network (headless cnn ie alexnet)\n",
    "        * decoder network (input a pic representation, outputs caption)\n",
    "* the most likely sentence\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
